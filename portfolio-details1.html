<!DOCTYPE html>
<html lang="en">

<head>
  <meta charset="utf-8">
  <meta content="width=device-width, initial-scale=1.0" name="viewport">

  <title>Project Details</title>
  <meta content="" name="descriptison">
  <meta content="" name="keywords">

  <!-- Favicons -->
  <link href="assets/img/favicon.png" rel="icon">
  <link href="assets/img/apple-touch-icon.png" rel="apple-touch-icon">

  <!-- Google Fonts -->
  <link href="https://fonts.googleapis.com/css?family=Open+Sans:300,300i,400,400i,600,600i,700,700i|Raleway:300,300i,400,400i,500,500i,600,600i,700,700i|Poppins:300,300i,400,400i,500,500i,600,600i,700,700i" rel="stylesheet">

  <!-- Vendor CSS Files -->
  <link href="assets/vendor/bootstrap/css/bootstrap.min.css" rel="stylesheet">
  <link href="assets/vendor/icofont/icofont.min.css" rel="stylesheet">
  <link href="assets/vendor/boxicons/css/boxicons.min.css" rel="stylesheet">
  <link href="assets/vendor/venobox/venobox.css" rel="stylesheet">
  <link href="assets/vendor/owl.carousel/assets/owl.carousel.min.css" rel="stylesheet">
  <link href="assets/vendor/aos/aos.css" rel="stylesheet">

  <!-- Template Main CSS File -->
  <link href="assets/css/style.css" rel="stylesheet">

</head>

<body>

  <!-- ======= Mobile nav toggle button ======= -->
  <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

  <!-- ======= Header ======= -->
  <header id="header">
    <div class="d-flex flex-column">

      <div class="profile">
        <img src="assets/img/profile_1.jpg" alt="" class="img-fluid rounded-circle">
        <h1 class="text-light"><a href="index.html">Veer Kalburgi</a></h1>
        <div class="social-links mt-3 text-center">
          <a href="https://github.com/veerkalburgi" class="github"><i class="bx bxl-github"></i></a>
          <a href="https://www.linkedin.com/in/veer-kalburgi-a2100550/" class="linkedin"><i class="bx bxl-linkedin"></i></a>          
          <a href="https://www.instagram.com/kalburgiveer/" class="instagram"><i class="bx bxl-instagram"></i></a>
          <a href="https://twitter.com/Veerkalburgi" class="twitter"><i class="bx bxl-twitter"></i></a>
          <a href="https://www.facebook.com/veer.kalburgi" class="facebook"><i class="bx bxl-facebook"></i></a>
        </div>
      </div>

     <nav class="nav-menu">
        <ul>
          <li><a href="index.html"><i class="bx bx-home"></i> <span>Home</span></a></li>
        </ul>
      </nav><!-- .nav-menu -->
      <button type="button" class="mobile-nav-toggle d-xl-none"><i class="icofont-navigation-menu"></i></button>

    </div>
  </header><!-- End Header -->

  <main id="main">

    <!-- ======= Breadcrumbs ======= -->
    <section id="breadcrumbs" class="breadcrumbs">
      <div class="container">

        <div class="d-flex justify-content-between align-items-center">
          <h2>Portfoio Details</h2>
          <ol>
            <li><a href="index.html">Home</a></li>
            <li>Project Details</li>
          </ol>
        </div>

      </div>
    </section><!-- End Breadcrumbs -->

    <!-- ======= Portfolio Details Section ======= -->
    <section id="portfolio-details" class="portfolio-details">
      <div class="container">

        <div class="portfolio-details-container">

          <div class="owl-carousel portfolio-details-carousel">
            <img src="assets/img/portfolio/portfolio_1.jpg" class="img-fluid" alt="">
          </div>

          <div class="portfolio-info">
            <h3>Self Driving Cars Specialization</h3>
            <ul>
              <li><strong>Category</strong>: Self-Driving Cars</li>
              <li><strong>Project date</strong>: August, 2020</li>
              <li><strong>Code URL</strong>: <a href=https://github.com/veerkalburgi/Self_Driving_Cars_Specialization"> github </a></li>
            </ul>
          </div>

        </div>

        <div class="portfolio-description">
          <h1><strong>Objective</strong></h1>
          <p>
            This Specialization gives you a comprehensive understanding of state-of-the-art engineering practices used in the self-driving car industry. You'll get to interact with real data sets from an autonomous vehicle (AV)―all through hands-on projects using the open-source simulator CARLA.
          </p>
            <br>
          <h1><strong>Tech Stack</strong></h1><p>Python, OpenCV, Tensorflow, Carla-Simulator,</p>
            <br>
          <h3><strong>Introduction to Self-Driving Cars</strong></h3>
            <p>
            This course will introduce you to the terminology, design considerations, and safety assessment of self-driving cars. By the end of this course, you will be able to: - Understand commonly used hardware used for self-driving cars - Identify the main components of the self-driving software stack - Program vehicle modeling and control - Analyze the safety frameworks and current industry practices for vehicle development For the final project in this course, you will develop control code to navigate a self-driving car around a racetrack in the CARLA simulation environment. You will construct longitudinal and lateral dynamic models for a vehicle and create controllers that regulate speed and path tracking performance using Python. You’ll test the limits of your control design and learn the challenges inherent in driving at the limit of vehicle performance. </p> 
            <br>
            <!--div>
                <p style="text-align:center;"><img src="assets/images/dog-vs-cat.jpg" alt="description of png"  style="width:650px;height:300px;">
				<div> <p style="text-align:center;"><i>Image Classification</i> </p></div>
            </div-->            
            <br>
            <h3><strong>State Estimation and Localization for Self-Driving Cars</strong></h3>
            <p>
This course will introduce you to the different sensors and how we can use them for state estimation and localization in a self-driving car. By the end of this course, you will be able to: - Understand the key methods for parameter and state estimation used for autonomous driving, such as the method of least-squares - Develop a model for typical vehicle localization sensors, including GPS and IMUs - Apply extended and unscented Kalman Filters to a vehicle state estimation problem - Understand LIDAR scan matching and the Iterative Closest Point algorithm - Apply these tools to fuse multiple sensor streams into a single state estimate for a self-driving car For the final project in this course, you will implement the Error-State Extended Kalman Filter (ES-EKF) to localize a vehicle using data from the CARLA simulator. </p>
            <br>
            <div>
                <p style="text-align:center;"><img src="assets/images/mlp-flatten.png" alt="description of png"  style="width:350px;height:280px;">
				<div> <p style="text-align:center;"><i>Flattening operation of small input matrix with pixel values in MLP</i> </p></div>
            </div>            
            <br>
            <h3><strong>Convolution Neural Networks</strong></h3> 
	            <p>The <b> CNN </b>yield better results in classifying images as compared to traditional linear and non linear classification algorithms. This is because they reduce the number of parameters to learn and there is no need of any preprocessing for feature-extraction. The CNNs uses convolutions of the image and the filter to extract complex invariant features at each layer. The complexity of features extracted increases with depth of layers (eg. [Layer 1: edges] -> [Layer 2: shapes] -> [Layer 3: pattern of shapes] -> .... -> output). They successfully capture the spatial and temporal dependancies within the image. The important features that make CNN special from others are, <b>Convolutions</b> and <b>Pooling</b>.</p> 
			<div>
                <p style="text-align:center;"><img src="assets/images/imageclassifier.gif" alt="description of gif"  style="width:800px;height:500px;">
            	<div> <p style="text-align:center;"><i>Image Classification using CNN</i> </p></div>
            </div>            
            <br>
            <br>
            <h4>1.<i> Convolutions</i></h4> 
            <div>
                <p style="text-align:center;"><img src="assets/images/no_padding_no_strides.gif" alt="description of gif"  style="width:200px;height:220px;">
            	<img src="assets/images/no_padding_strides.gif" alt="description of gif"  style="width:200px;height:220px;">
            	<img src="assets/images/no_padding_no_strides_transposed.gif" alt="description of gif"  style="width:200px;height:220px;">
            	<img src="assets/images/full_padding_no_strides_transposed.gif" alt="description of gif"  style="width:200px;height:220px;">
            	<br>
            	<div> <p style="text-align:center;"><i>Convolutions in CNN</i>, Blue: <i>Input</i> and Green: <i>Output</i></p></div>
            </div>
            <p>
            <p>A convolution is a type of matrix operation, consisting of a kernel, a small matrix of weights, that slides over input data performing element-wise multiplication with the part of the input it is on, then summing the results into an output.
            </p>These are basically merging two sets of information. Mathematically, convolution refers to combination of two function to yield third function. In the case of CNN, convolution is the application of filters/kernels to an input image resulting in activations. Feature maps are what we get on repeated applications of such filters over the input. These feature map indicate the locations learned and strength of detected feature of input, i.e., they summarize the presence of detected features in input. The simple MLP does not consider the order and importance of neighbouring pixels. CNN on other hand, as described above, takes the advantage using convolutions.</p> 
            <p>
            The problem of feature maps is that these are sensitive to locations of features in input. One way to adress the issue is to down sample the feature map. This is addressed by <i>pooling</i>.   
            </p>
            <h4>2.<i> Pooling</i></h4>
            <p>Pooling layers provide an approach to down sampling feature maps by summarizing the presence of features in patches of the feature map. Two common pooling methods are average pooling and max pooling. 
            <div>
                <p style="text-align:center;"><img src="assets/images/pooling.png" alt="description of gif"  style="width:400px;height:400px;">
            	<br>
            	<div> <p style="text-align:center;"><i>Max Pooling and Average Pooling in CNN </i></p></div>
            </div>
            <br><br>
            The above discussed are the reasons why I chose CNN architecture for the purpose of image classification. Further, I used pretrained models to classify the target dataset, dog images. </p>
            <br>
          <h3><strong>Transfer Learning</strong></h3>  
            <p>The <b>Transfer learning</b> approach, is utilizing the selected pretrained network and then adapting of neural network to a new (similar) dataset. The approach keeps all the convolutional layers but replacing the final fully connected layers with another neural network. The base network "transfers" the learnt features to targeted network.
            </p>
            <div>
                <p style="text-align:center;"><img src="assets/images/transfer.jpeg" alt="description"  style="width:600px;height:250px;">
            </div>            
        </div>
        	<p><i>Among the wide range of pretrained CNN architecture I have chosen the classic models such as VGG, AlexNet, and ResNet. With the help of deep learning and computer vision frameworks, like PyTorch and OpenCV, I have developed the scripts to get accuarate predictions and good results over unseen data. Following are glimpses of my model classifying few test images of dogs into their breeds. To view the code and detailed results, follow link shared in the description box.</i></p>
        	<div>
        		<p style="text-align:center;"><img src="assets/images/2.png"   style="width:280px;height:220px;">
            	<img src="assets/images/3.png"   style="width:260px;height:220px;">
            	<img src="assets/images/5.png"   style="width:260px;height:220px;">
            	<img src="assets/images/4.png"   style="width:270px;height:220px;">
        	</div>
        	<br>
			<h1><strong>References</strong></h1>
			<p>
				<li><a href="https://www.udacity.com/course/deep-learning-nanodegree--nd101">Udacity Deep Learning Nanodegree</a> and my <a href="https://github.com/pr2tik1/dog-classifier">Project</a></li>
				<li><a href="https://cs231n.github.io/">CS231n</a></li>
				<li><a href="https://d2l.ai/">Dive Deep into Deep Learning</a></li>
				<li><a href="http://www.deeplearningbook.org/">Deep Learning</a></li>
				<li><a href="https://machinelearningmastery.com/">Machine Learnning Mastery</a></li>
			</p>        	
      </div>
    </section><!-- End Portfolio Details Section -->

  <!-- Site footer -->
    <footer class="site-footer">
      <div class="container">
           <div>
            <p class="text-center">Made with Love ❤️ | Inspired by <a href="https://bootstrapmade.com/iportfolio-bootstrap-portfolio-websites-template/">Bootstrapmade.com</a></p>
          </div>
      </div>
</footer>

  </main><!-- End #main -->


  <a href="#" class="back-to-top"><i class="icofont-simple-up"></i></a>

  <!-- Vendor JS Files -->
  <script src="assets/vendor/jquery/jquery.min.js"></script>
  <script src="assets/vendor/bootstrap/js/bootstrap.bundle.min.js"></script>
  <script src="assets/vendor/jquery.easing/jquery.easing.min.js"></script>
  <script src="assets/vendor/php-email-form/validate.js"></script>
  <script src="assets/vendor/waypoints/jquery.waypoints.min.js"></script>
  <script src="assets/vendor/counterup/counterup.min.js"></script>
  <script src="assets/vendor/isotope-layout/isotope.pkgd.min.js"></script>
  <script src="assets/vendor/venobox/venobox.min.js"></script>
  <script src="assets/vendor/owl.carousel/owl.carousel.min.js"></script>
  <script src="assets/vendor/typed.js/typed.min.js"></script>
  <script src="assets/vendor/aos/aos.js"></script>

  <!-- Template Main JS File -->
  <script src="assets/js/main.js"></script>

</body>

</html>
